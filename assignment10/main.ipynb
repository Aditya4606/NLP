{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "859a8149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and parsing data from wsj_pos_tagged_en.txt...\n",
      "Found 3914 sentences.\n",
      "Starting 5-Fold Cross-Validation...\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Training HMM (calculating probabilities)...\n",
      "  -> Saving probability tables for Fold 1...\n",
      "     Saved 'transitions_fold_1.csv' and 'emissions_fold_1.csv'\n",
      "Predicting tags on test set...\n",
      "Results for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           #       0.00      0.00      0.00         1\n",
      "           $       0.76      1.00      0.86       129\n",
      "          ''       0.75      1.00      0.86       148\n",
      "           ,       0.95      1.00      0.98       953\n",
      "       -LRB-       1.00      0.54      0.70        24\n",
      "       -RRB-       0.95      0.74      0.83        27\n",
      "           .       0.90      1.00      0.95       782\n",
      "           :       1.00      0.89      0.94       105\n",
      "          CC       0.99      0.99      0.99       451\n",
      "          CD       0.95      0.71      0.81       717\n",
      "          DT       0.79      0.98      0.88      1627\n",
      "          EX       1.00      0.65      0.79        17\n",
      "          FW       0.00      0.00      0.00         1\n",
      "          IN       0.86      0.97      0.91      1942\n",
      "          JJ       0.72      0.72      0.72      1219\n",
      "         JJR       0.62      0.48      0.54        54\n",
      "         JJS       0.30      0.07      0.12        41\n",
      "          LS       0.00      0.00      0.00         5\n",
      "          MD       0.89      0.99      0.94       193\n",
      "          NN       0.84      0.88      0.86      2649\n",
      "         NNP       0.83      0.85      0.84      1793\n",
      "        NNPS       1.00      0.04      0.08        47\n",
      "         NNS       0.91      0.75      0.82      1122\n",
      "         PDT       0.00      0.00      0.00         5\n",
      "         POS       0.92      0.98      0.95       172\n",
      "         PRP       0.85      0.95      0.90       365\n",
      "        PRP$       0.99      0.93      0.96       151\n",
      "          RB       0.89      0.64      0.74       575\n",
      "         RBR       0.75      0.10      0.18        30\n",
      "         RBS       0.00      0.00      0.00         9\n",
      "          RP       0.53      0.21      0.30        38\n",
      "          TO       0.96      1.00      0.98       461\n",
      "          UH       0.00      0.00      0.00         1\n",
      "          VB       0.86      0.91      0.88       526\n",
      "         VBD       0.91      0.81      0.86       605\n",
      "         VBG       0.86      0.37      0.52       291\n",
      "         VBN       0.65      0.64      0.65       428\n",
      "         VBP       0.92      0.71      0.80       259\n",
      "         VBZ       0.94      0.76      0.84       431\n",
      "         WDT       0.94      0.73      0.82        89\n",
      "          WP       1.00      0.69      0.81        48\n",
      "         WP$       0.00      0.00      0.00         1\n",
      "         WRB       0.92      0.39      0.55        28\n",
      "          ``       0.91      0.93      0.92       148\n",
      "\n",
      "    accuracy                           0.85     18708\n",
      "   macro avg       0.72      0.61      0.64     18708\n",
      "weighted avg       0.86      0.85      0.85     18708\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Training HMM (calculating probabilities)...\n",
      "  -> Saving probability tables for Fold 2...\n",
      "     Saved 'transitions_fold_2.csv' and 'emissions_fold_2.csv'\n",
      "Predicting tags on test set...\n",
      "Results for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           #       0.00      0.00      0.00        10\n",
      "           $       0.69      1.00      0.81       138\n",
      "          ''       0.68      0.99      0.81       143\n",
      "           ,       0.94      1.00      0.97       950\n",
      "       -LRB-       1.00      0.43      0.60        30\n",
      "       -RRB-       1.00      0.73      0.85        30\n",
      "           .       0.88      1.00      0.94       776\n",
      "           :       1.00      0.92      0.96        97\n",
      "          CC       1.00      0.98      0.99       434\n",
      "          CD       0.95      0.73      0.83       739\n",
      "          DT       0.78      0.99      0.87      1631\n",
      "          EX       1.00      0.68      0.81        19\n",
      "          FW       0.00      0.00      0.00         1\n",
      "          IN       0.85      0.98      0.91      2001\n",
      "          JJ       0.74      0.74      0.74      1183\n",
      "         JJR       0.77      0.43      0.55        83\n",
      "         JJS       0.78      0.22      0.34        32\n",
      "          LS       0.00      0.00      0.00         1\n",
      "          MD       0.90      0.98      0.94       185\n",
      "          NN       0.82      0.87      0.85      2687\n",
      "         NNP       0.84      0.84      0.84      1834\n",
      "        NNPS       1.00      0.09      0.16        57\n",
      "         NNS       0.91      0.74      0.82      1235\n",
      "         PDT       0.00      0.00      0.00         6\n",
      "         POS       0.93      0.99      0.96       172\n",
      "         PRP       0.78      0.95      0.86       307\n",
      "        PRP$       1.00      0.92      0.96       148\n",
      "          RB       0.88      0.63      0.74       594\n",
      "         RBR       1.00      0.14      0.24        29\n",
      "         RBS       0.00      0.00      0.00         4\n",
      "          RP       0.71      0.20      0.31        50\n",
      "          TO       0.97      0.99      0.98       417\n",
      "          VB       0.84      0.86      0.85       510\n",
      "         VBD       0.91      0.76      0.83       621\n",
      "         VBG       0.82      0.29      0.43       315\n",
      "         VBN       0.65      0.66      0.66       405\n",
      "         VBP       0.91      0.71      0.79       256\n",
      "         VBZ       0.92      0.77      0.84       427\n",
      "         WDT       0.90      0.74      0.81        97\n",
      "          WP       1.00      0.65      0.79        51\n",
      "         WP$       0.00      0.00      0.00         1\n",
      "         WRB       0.93      0.39      0.55        36\n",
      "          ``       0.92      0.91      0.92       149\n",
      "\n",
      "    accuracy                           0.85     18891\n",
      "   macro avg       0.76      0.63      0.65     18891\n",
      "weighted avg       0.85      0.85      0.84     18891\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Training HMM (calculating probabilities)...\n",
      "  -> Saving probability tables for Fold 3...\n",
      "     Saved 'transitions_fold_3.csv' and 'emissions_fold_3.csv'\n",
      "Predicting tags on test set...\n",
      "Results for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           #       0.00      0.00      0.00         1\n",
      "           $       0.83      1.00      0.91       158\n",
      "          ''       0.65      1.00      0.79       115\n",
      "           ,       0.95      1.00      0.97       975\n",
      "       -LRB-       1.00      0.68      0.81        19\n",
      "       -RRB-       1.00      0.79      0.88        19\n",
      "           .       0.90      1.00      0.95       772\n",
      "           :       1.00      0.94      0.97        96\n",
      "          CC       0.99      0.99      0.99       444\n",
      "          CD       0.95      0.79      0.86       699\n",
      "          DT       0.79      0.98      0.87      1600\n",
      "          EX       1.00      0.73      0.84        11\n",
      "          IN       0.87      0.97      0.92      1942\n",
      "          JJ       0.73      0.75      0.74      1095\n",
      "         JJR       0.71      0.48      0.57        81\n",
      "         JJS       0.55      0.14      0.23        42\n",
      "          MD       0.94      0.98      0.96       197\n",
      "          NN       0.83      0.88      0.85      2534\n",
      "         NNP       0.87      0.84      0.86      1834\n",
      "        NNPS       0.00      0.00      0.00        45\n",
      "         NNS       0.92      0.75      0.83      1207\n",
      "         PDT       0.00      0.00      0.00         8\n",
      "         POS       0.91      0.99      0.95       152\n",
      "         PRP       0.81      0.95      0.87       369\n",
      "        PRP$       0.99      0.92      0.95       159\n",
      "          RB       0.85      0.68      0.76       542\n",
      "         RBR       0.67      0.15      0.24        27\n",
      "         RBS       0.00      0.00      0.00         8\n",
      "          RP       0.58      0.17      0.26        41\n",
      "         SYM       0.00      0.00      0.00         1\n",
      "          TO       0.98      1.00      0.99       453\n",
      "          VB       0.87      0.88      0.87       536\n",
      "         VBD       0.90      0.81      0.85       639\n",
      "         VBG       0.89      0.35      0.50       264\n",
      "         VBN       0.69      0.63      0.66       457\n",
      "         VBP       0.92      0.72      0.81       262\n",
      "         VBZ       0.93      0.79      0.85       393\n",
      "         WDT       0.94      0.80      0.87        81\n",
      "          WP       0.97      0.70      0.82        54\n",
      "         WP$       0.00      0.00      0.00         4\n",
      "         WRB       0.93      0.48      0.64        29\n",
      "          ``       0.86      0.91      0.88       126\n",
      "\n",
      "    accuracy                           0.86     18491\n",
      "   macro avg       0.74      0.66      0.68     18491\n",
      "weighted avg       0.86      0.86      0.85     18491\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Training HMM (calculating probabilities)...\n",
      "  -> Saving probability tables for Fold 4...\n",
      "     Saved 'transitions_fold_4.csv' and 'emissions_fold_4.csv'\n",
      "Predicting tags on test set...\n",
      "Results for Fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           $       0.70      1.00      0.82       110\n",
      "          ''       0.67      0.99      0.80       144\n",
      "           ,       0.96      1.00      0.98       961\n",
      "       -LRB-       1.00      0.52      0.69        21\n",
      "       -RRB-       1.00      0.88      0.93        24\n",
      "           .       0.89      1.00      0.94       773\n",
      "           :       1.00      0.93      0.96       137\n",
      "          CC       0.99      0.98      0.99       471\n",
      "          CD       0.92      0.71      0.80       619\n",
      "          DT       0.78      0.99      0.87      1648\n",
      "          EX       1.00      0.75      0.86        20\n",
      "          IN       0.86      0.98      0.92      1976\n",
      "          JJ       0.73      0.69      0.71      1184\n",
      "         JJR       0.78      0.51      0.62        74\n",
      "         JJS       0.58      0.19      0.29        37\n",
      "          LS       0.00      0.00      0.00         5\n",
      "          MD       0.90      0.97      0.93       186\n",
      "          NN       0.80      0.87      0.83      2594\n",
      "         NNP       0.84      0.84      0.84      1937\n",
      "        NNPS       1.00      0.02      0.04        53\n",
      "         NNS       0.94      0.72      0.82      1267\n",
      "         PDT       0.00      0.00      0.00         6\n",
      "         POS       0.92      0.98      0.95       159\n",
      "         PRP       0.84      0.93      0.89       351\n",
      "        PRP$       0.99      0.92      0.95       164\n",
      "          RB       0.87      0.65      0.75       577\n",
      "         RBR       1.00      0.17      0.29        24\n",
      "         RBS       0.00      0.00      0.00         7\n",
      "          RP       0.87      0.27      0.41        49\n",
      "          TO       0.96      1.00      0.98       441\n",
      "          UH       0.00      0.00      0.00         2\n",
      "          VB       0.81      0.88      0.84       507\n",
      "         VBD       0.92      0.79      0.85       572\n",
      "         VBG       0.77      0.30      0.43       272\n",
      "         VBN       0.66      0.67      0.67       446\n",
      "         VBP       0.83      0.66      0.73       268\n",
      "         VBZ       0.95      0.80      0.87       462\n",
      "         WDT       0.96      0.70      0.81       100\n",
      "          WP       1.00      0.68      0.81        47\n",
      "         WP$       0.00      0.00      0.00         5\n",
      "         WRB       0.85      0.26      0.39        43\n",
      "          ``       0.94      0.93      0.93       140\n",
      "\n",
      "    accuracy                           0.85     18883\n",
      "   macro avg       0.77      0.65      0.67     18883\n",
      "weighted avg       0.85      0.85      0.84     18883\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Training HMM (calculating probabilities)...\n",
      "  -> Saving probability tables for Fold 5...\n",
      "     Saved 'transitions_fold_5.csv' and 'emissions_fold_5.csv'\n",
      "Predicting tags on test set...\n",
      "Results for Fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           #       0.00      0.00      0.00         4\n",
      "           $       0.83      1.00      0.91       189\n",
      "          ''       0.70      1.00      0.82       144\n",
      "           ,       0.96      1.00      0.98      1047\n",
      "       -LRB-       1.00      0.23      0.38        26\n",
      "       -RRB-       1.00      0.50      0.67        26\n",
      "           .       0.89      1.00      0.94       771\n",
      "           :       1.00      0.95      0.98       128\n",
      "          CC       1.00      0.99      0.99       465\n",
      "          CD       0.96      0.78      0.86       772\n",
      "          DT       0.78      0.99      0.88      1659\n",
      "          EX       1.00      0.90      0.95        21\n",
      "          FW       0.00      0.00      0.00         2\n",
      "          IN       0.86      0.98      0.92      1996\n",
      "          JJ       0.74      0.76      0.75      1153\n",
      "         JJR       0.72      0.38      0.50        89\n",
      "         JJS       0.70      0.23      0.35        30\n",
      "          LS       0.00      0.00      0.00         2\n",
      "          MD       0.86      0.99      0.92       166\n",
      "          NN       0.83      0.88      0.86      2702\n",
      "         NNP       0.86      0.86      0.86      2012\n",
      "        NNPS       1.00      0.02      0.05        42\n",
      "         NNS       0.92      0.73      0.81      1216\n",
      "         PDT       0.00      0.00      0.00         2\n",
      "         POS       0.96      1.00      0.98       169\n",
      "         PRP       0.84      0.95      0.89       324\n",
      "        PRP$       1.00      0.94      0.97       144\n",
      "          RB       0.89      0.64      0.74       534\n",
      "         RBR       1.00      0.12      0.21        26\n",
      "         RBS       0.00      0.00      0.00         7\n",
      "          RP       0.88      0.18      0.30        38\n",
      "          TO       0.96      1.00      0.98       407\n",
      "          VB       0.82      0.86      0.84       475\n",
      "         VBD       0.89      0.79      0.84       606\n",
      "         VBG       0.88      0.31      0.46       318\n",
      "         VBN       0.67      0.66      0.66       398\n",
      "         VBP       0.88      0.59      0.71       276\n",
      "         VBZ       0.95      0.79      0.86       412\n",
      "         WDT       0.84      0.63      0.72        78\n",
      "          WP       1.00      0.71      0.83        41\n",
      "         WP$       0.00      0.00      0.00         3\n",
      "         WRB       0.92      0.29      0.44        42\n",
      "          ``       0.92      0.93      0.93       149\n",
      "\n",
      "    accuracy                           0.86     19111\n",
      "   macro avg       0.77      0.62      0.64     19111\n",
      "weighted avg       0.86      0.86      0.85     19111\n",
      "\n",
      "\n",
      "--- Average Performance Across All Folds ---\n",
      "Average Accuracy:  0.8538\n",
      "Average Precision (Macro): 0.7525\n",
      "Average Recall (Macro):    0.6323\n",
      "Average F1-Score (Macro):  0.6576\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd  # Added pandas for CSV handling\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "import sys\n",
    "\n",
    "# --- 1. Data Parsing ---\n",
    "\n",
    "def parse_sentences(file_path):\n",
    "    \"\"\"\n",
    "    Parses the tagged file into a list of sentences.\n",
    "    Each sentence is a list of (word, tag) tuples.\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            sentence = []\n",
    "            pairs = line.split(' ')\n",
    "            for pair in pairs:\n",
    "                # Find the last underscore to split word and tag\n",
    "                split_index = pair.rfind('_')\n",
    "                if split_index == -1:\n",
    "                    continue # Skip if format is incorrect\n",
    "                \n",
    "                word = pair[:split_index]\n",
    "                tag = pair[split_index+1:]\n",
    "                sentence.append((word, tag))\n",
    "            \n",
    "            if sentence:\n",
    "                sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# --- 2. HMM Model Training (Task b) ---\n",
    "\n",
    "def train_hmm(train_sentences, smoothing_k=1):\n",
    "    \"\"\"\n",
    "    Calculates transition and emission probabilities from the training data.\n",
    "    \n",
    "    Returns:\n",
    "    - transition_probs: logP(tag_i | tag_i-1)\n",
    "    - emission_probs: logP(word | tag)\n",
    "    - all_tags: A set of all unique tags\n",
    "    \"\"\"\n",
    "    \n",
    "    transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "    emission_counts = defaultdict(lambda: defaultdict(int))\n",
    "    tag_counts = defaultdict(int)\n",
    "    all_tags = set()\n",
    "    vocab = set()\n",
    "\n",
    "    # --- Count occurrences ---\n",
    "    for sentence in train_sentences:\n",
    "        prev_tag = \"START\" # Special tag for the beginning of a sentence\n",
    "        \n",
    "        for i, (word, tag) in enumerate(sentence):\n",
    "            # Add to vocab and tag set\n",
    "            vocab.add(word)\n",
    "            all_tags.add(tag)\n",
    "            \n",
    "            # Count tag\n",
    "            tag_counts[tag] += 1\n",
    "            \n",
    "            # Count transition (prev_tag -> tag)\n",
    "            transition_counts[prev_tag][tag] += 1\n",
    "            \n",
    "            # Count emission (tag -> word)\n",
    "            emission_counts[tag][word] += 1\n",
    "            \n",
    "            prev_tag = tag\n",
    "\n",
    "    # --- Calculate Log Probabilities with Add-k Smoothing ---\n",
    "    \n",
    "    num_tags = len(all_tags)\n",
    "    vocab_size = len(vocab)\n",
    "    \n",
    "    # -- Transition Probabilities: logP(tag | prev_tag) --\n",
    "    transition_probs = defaultdict(lambda: defaultdict(float))\n",
    "    \n",
    "    # Handle START tag separately\n",
    "    start_tag_total = sum(transition_counts[\"START\"].values())\n",
    "    for tag in all_tags:\n",
    "        count = transition_counts[\"START\"][tag]\n",
    "        prob = (count + smoothing_k) / (start_tag_total + smoothing_k * num_tags)\n",
    "        transition_probs[\"START\"][tag] = np.log(prob)\n",
    "        \n",
    "    # Handle all other tags\n",
    "    for prev_tag in all_tags:\n",
    "        total_transitions_from_prev = sum(transition_counts[prev_tag].values())\n",
    "        \n",
    "        for tag in all_tags:\n",
    "            count = transition_counts[prev_tag][tag]\n",
    "            prob = (count + smoothing_k) / (total_transitions_from_prev + smoothing_k * num_tags)\n",
    "            transition_probs[prev_tag][tag] = np.log(prob)\n",
    "\n",
    "    # -- Emission Probabilities: logP(word | tag) --\n",
    "    emission_probs = defaultdict(lambda: defaultdict(float))\n",
    "    \n",
    "    # Calculate log probability for unknown words\n",
    "    unknown_log_prob = {}\n",
    "    for tag in all_tags:\n",
    "        # Prob for <UNK> token\n",
    "        prob = smoothing_k / (tag_counts[tag] + smoothing_k * (vocab_size + 1))\n",
    "        unknown_log_prob[tag] = np.log(prob)\n",
    "        \n",
    "    for tag in all_tags:\n",
    "        total_emissions_from_tag = tag_counts[tag]\n",
    "        \n",
    "        for word in vocab:\n",
    "            count = emission_counts[tag][word]\n",
    "            prob = (count + smoothing_k) / (total_emissions_from_tag + smoothing_k * (vocab_size + 1))\n",
    "            emission_probs[tag][word] = np.log(prob)\n",
    "            \n",
    "        # Add the <UNK> probability for this tag\n",
    "        emission_probs[tag][\"<UNK>\"] = unknown_log_prob[tag]\n",
    "\n",
    "    return transition_probs, emission_probs, all_tags\n",
    "\n",
    "\n",
    "# --- 3. Helper Function to Save to CSV ---\n",
    "\n",
    "def save_model_to_csv(transition_probs, emission_probs, fold_num):\n",
    "    \"\"\"\n",
    "    Converts probability dictionaries to DataFrames, converts log-probs to \n",
    "    normal probabilities, and saves them as CSVs.\n",
    "    \"\"\"\n",
    "    print(f\"  -> Saving probability tables for Fold {fold_num}...\")\n",
    "\n",
    "    # --- Save Transition Probabilities ---\n",
    "    # Convert nested dict to DataFrame (Rows=Prev Tag, Cols=Next Tag)\n",
    "    df_trans = pd.DataFrame(transition_probs).T \n",
    "    # Convert Log Probs back to Normal Probs (0 to 1) and fill NaNs\n",
    "    df_trans = df_trans.map(np.exp).fillna(0) \n",
    "    \n",
    "    trans_filename = f\"transitions_fold_{fold_num}.csv\"\n",
    "    df_trans.to_csv(trans_filename)\n",
    "\n",
    "    # --- Save Emission Probabilities ---\n",
    "    # Convert nested dict to DataFrame (Rows=Tag, Cols=Word)\n",
    "    df_emit = pd.DataFrame(emission_probs).T\n",
    "    # Convert Log Probs back to Normal Probs\n",
    "    df_emit = df_emit.map(np.exp).fillna(0)\n",
    "    \n",
    "    emit_filename = f\"emissions_fold_{fold_num}.csv\"\n",
    "    df_emit.to_csv(emit_filename)\n",
    "    print(f\"     Saved '{trans_filename}' and '{emit_filename}'\")\n",
    "\n",
    "\n",
    "# --- 4. Viterbi Algorithm (Task c) ---\n",
    "\n",
    "def viterbi_decode(sentence_words, all_tags, transition_probs, emission_probs):\n",
    "    \"\"\"\n",
    "    Predicts the most likely tag sequence for a given sentence.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_tags = len(all_tags)\n",
    "    num_words = len(sentence_words)\n",
    "    tags_list = sorted(list(all_tags)) \n",
    "    \n",
    "    # Viterbi matrix\n",
    "    viterbi = np.full((num_tags, num_words), -np.inf) \n",
    "    backpointers = np.zeros((num_tags, num_words), dtype=int)\n",
    "    \n",
    "    # --- Initialization Step ---\n",
    "    for i, tag in enumerate(tags_list):\n",
    "        word = sentence_words[0]\n",
    "        if word not in emission_probs[tag]:\n",
    "            word = \"<UNK>\"\n",
    "        \n",
    "        log_emission = emission_probs[tag][word]\n",
    "        log_transition = transition_probs[\"START\"][tag]\n",
    "        \n",
    "        viterbi[i, 0] = log_transition + log_emission\n",
    "\n",
    "    # --- Recursion Step ---\n",
    "    for t in range(1, num_words):\n",
    "        word = sentence_words[t]\n",
    "        \n",
    "        for j, current_tag in enumerate(tags_list):\n",
    "            if word not in emission_probs[current_tag]:\n",
    "                word_to_check = \"<UNK>\"\n",
    "            else:\n",
    "                word_to_check = word\n",
    "            \n",
    "            log_emission = emission_probs[current_tag][word_to_check]\n",
    "\n",
    "            max_prob = -np.inf\n",
    "            best_prev_tag_index = 0\n",
    "            \n",
    "            for i, prev_tag in enumerate(tags_list):\n",
    "                log_transition = transition_probs[prev_tag][current_tag]\n",
    "                current_prob = viterbi[i, t-1] + log_transition + log_emission\n",
    "                \n",
    "                if current_prob > max_prob:\n",
    "                    max_prob = current_prob\n",
    "                    best_prev_tag_index = i\n",
    "            \n",
    "            viterbi[j, t] = max_prob\n",
    "            backpointers[j, t] = best_prev_tag_index\n",
    "\n",
    "    # --- Termination Step ---\n",
    "    best_last_tag_index = np.argmax(viterbi[:, -1])\n",
    "    \n",
    "    # --- Backtracking ---\n",
    "    best_path = [tags_list[best_last_tag_index]]\n",
    "    current_tag_index = best_last_tag_index\n",
    "    \n",
    "    for t in range(num_words - 1, 0, -1):\n",
    "        prev_tag_index = backpointers[current_tag_index, t]\n",
    "        best_path.insert(0, tags_list[prev_tag_index])\n",
    "        current_tag_index = prev_tag_index\n",
    "        \n",
    "    return best_path\n",
    "\n",
    "\n",
    "# --- 5. Main Execution: K-Fold CV and Evaluation (Tasks a & d) ---\n",
    "\n",
    "def main():\n",
    "    FILE_PATH = \"wsj_pos_tagged_en.txt\"\n",
    "    K_FOLDS = 5 # As per assignment, K >= 3\n",
    "    \n",
    "    print(f\"Loading and parsing data from {FILE_PATH}...\")\n",
    "    try:\n",
    "        sentences = parse_sentences(FILE_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at '{FILE_PATH}'\")\n",
    "        print(\"Please make sure 'wsj_pos_tagged_en.txt' is in the same directory.\")\n",
    "        return # Changed sys.exit to return for notebook safety\n",
    "        \n",
    "    if not sentences:\n",
    "        print(\"Error: No sentences were parsed. Check file format.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(sentences)} sentences.\")\n",
    "    print(f\"Starting {K_FOLDS}-Fold Cross-Validation...\\n\")\n",
    "\n",
    "    kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "    sentences_array = np.array(sentences, dtype=object) \n",
    "    \n",
    "    fold_reports = []\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(sentences_array)):\n",
    "        print(f\"--- Fold {fold+1}/{K_FOLDS} ---\")\n",
    "        \n",
    "        train_sentences = sentences_array[train_index]\n",
    "        test_sentences = sentences_array[test_index]\n",
    "        \n",
    "        # --- Task b: Train the HMM ---\n",
    "        print(\"Training HMM (calculating probabilities)...\")\n",
    "        transition_probs, emission_probs, all_tags = train_hmm(train_sentences)\n",
    "        \n",
    "        # --- NEW STEP: Save tables to CSV ---\n",
    "        save_model_to_csv(transition_probs, emission_probs, fold+1)\n",
    "        # ------------------------------------\n",
    "\n",
    "        # --- Tasks c & d: Predict and Evaluate ---\n",
    "        print(\"Predicting tags on test set...\")\n",
    "        all_true_tags = []\n",
    "        all_pred_tags = []\n",
    "        \n",
    "        for sentence in test_sentences:\n",
    "            words = [word for word, tag in sentence]\n",
    "            true_tags = [tag for word, tag in sentence]\n",
    "            \n",
    "            # Task c: Viterbi Decode\n",
    "            pred_tags = viterbi_decode(words, all_tags, transition_probs, emission_probs)\n",
    "            \n",
    "            all_true_tags.extend(true_tags)\n",
    "            all_pred_tags.extend(pred_tags)\n",
    "\n",
    "        # Task d: Evaluate Performance for this fold\n",
    "        report = classification_report(all_true_tags, all_pred_tags, zero_division=0)\n",
    "        print(f\"Results for Fold {fold+1}:\")\n",
    "        print(report)\n",
    "        fold_reports.append(classification_report(all_true_tags, all_pred_tags, output_dict=True, zero_division=0))\n",
    "\n",
    "    # --- Final Averaged Results ---\n",
    "    print(\"\\n--- Average Performance Across All Folds ---\")\n",
    "    \n",
    "    avg_precision = np.mean([r['macro avg']['precision'] for r in fold_reports])\n",
    "    avg_recall = np.mean([r['macro avg']['recall'] for r in fold_reports])\n",
    "    avg_f1 = np.mean([r['macro avg']['f1-score'] for r in fold_reports])\n",
    "    avg_accuracy = np.mean([r['accuracy'] for r in fold_reports])\n",
    "    \n",
    "    print(f\"Average Accuracy:  {avg_accuracy:.4f}\")\n",
    "    print(f\"Average Precision (Macro): {avg_precision:.4f}\")\n",
    "    print(f\"Average Recall (Macro):    {avg_recall:.4f}\")\n",
    "    print(f\"Average F1-Score (Macro):  {avg_f1:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
