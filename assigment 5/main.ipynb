{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe4994c",
   "metadata": {},
   "source": [
    "<h1>generating random 1000 lines from tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b616b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "input_file = \"tokenized_sentences.txt\"\n",
    "train_file = \"train.txt\"\n",
    "valid_file = \"validation.txt\"\n",
    "test_file = \"test.txt\"\n",
    "\n",
    "# Reservoir sampling for validation & test\n",
    "valid_size, test_size = 1000, 1000\n",
    "valid, test = [], []\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, \\\n",
    "     open(train_file, \"w\", encoding=\"utf-8\", buffering=1024*1024) as train_out, \\\n",
    "     open(valid_file, \"w\", encoding=\"utf-8\", buffering=1024*1024) as valid_out, \\\n",
    "     open(test_file, \"w\", encoding=\"utf-8\", buffering=1024*1024) as test_out:\n",
    "\n",
    "    for idx, line in enumerate(infile, 1):\n",
    "        # Validation sampling\n",
    "        if len(valid) < valid_size:\n",
    "            valid.append(line)\n",
    "        elif random.random() < valid_size / idx:\n",
    "            replace_idx = random.randint(0, valid_size - 1)\n",
    "            train_out.write(valid[replace_idx])\n",
    "            valid[replace_idx] = line\n",
    "            continue\n",
    "\n",
    "        # Test sampling\n",
    "        elif len(test) < test_size:\n",
    "            test.append(line)\n",
    "        elif random.random() < test_size / idx:\n",
    "            replace_idx = random.randint(0, test_size - 1)\n",
    "            train_out.write(test[replace_idx])\n",
    "            test[replace_idx] = line\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            train_out.write(line)\n",
    "\n",
    "    # At the end, flush validation & test\n",
    "    valid_out.writelines(valid)\n",
    "    test_out.writelines(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380666e1",
   "metadata": {},
   "source": [
    "<h1>applying good turing smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8d83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good-Turing models built.\n",
      "Processed 100 sentences from validation.txt\n",
      "Processed 200 sentences from validation.txt\n",
      "Processed 300 sentences from validation.txt\n",
      "Processed 400 sentences from validation.txt\n",
      "Processed 500 sentences from validation.txt\n",
      "Processed 600 sentences from validation.txt\n",
      "Processed 700 sentences from validation.txt\n",
      "Processed 800 sentences from validation.txt\n",
      "Processed 900 sentences from validation.txt\n",
      "Processed 1000 sentences from validation.txt\n",
      "Processed 100 sentences from test.txt\n",
      "Processed 200 sentences from test.txt\n",
      "Processed 300 sentences from test.txt\n",
      "Processed 400 sentences from test.txt\n",
      "Processed 500 sentences from test.txt\n",
      "Processed 600 sentences from test.txt\n",
      "Processed 700 sentences from test.txt\n",
      "Processed 800 sentences from test.txt\n",
      "Processed 900 sentences from test.txt\n",
      "Processed 1000 sentences from test.txt\n",
      "Sentence log-probabilities saved to validation_probs.csv and test_probs.csv\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import collections\n",
    "import math\n",
    "import csv\n",
    "\n",
    "# ---------------- Load Pickle ----------------\n",
    "def load_ngram_counts(n):\n",
    "    file_name = f\"ngram_counts_{n}gram.pkl\"\n",
    "    with open(file_name, \"rb\") as f:\n",
    "        counts = pickle.load(f)\n",
    "    return counts\n",
    "\n",
    "# ---------------- Vocabulary ----------------\n",
    "def get_vocabulary(unigrams):\n",
    "    return set([token[0] for token in unigrams.keys()])\n",
    "\n",
    "# ---------------- Good-Turing Smoothing ----------------\n",
    "def good_turing_smoothing(ngrams, vocab_size, n):\n",
    "    N = sum(ngrams.values())  # total seen n-grams\n",
    "    Nc = collections.Counter(ngrams.values())  # frequency of frequency\n",
    "    N1 = Nc.get(1, 0)\n",
    "\n",
    "    smoothed_probs = {}\n",
    "    for ngram, c in ngrams.items():\n",
    "        Nc_plus1 = Nc.get(c + 1, 0)\n",
    "        if Nc_plus1 > 0 and Nc[c] > 0:\n",
    "            c_star = (c + 1) * (Nc_plus1 / Nc[c]) #updation of count for seen probability\n",
    "        else:\n",
    "            c_star = c\n",
    "        smoothed_probs[ngram] = c_star / N   #unseen probability\n",
    "\n",
    "    # Unseen probability \n",
    "    if n == 1:   #no of unseen unigrams\n",
    "        U = len(ngrams) \n",
    "        num_unseen = max(1, vocab_size - U) #vocab size - unique unigrams\n",
    "    else:\n",
    "        num_unseen = max(1, (vocab_size ** n) - len(ngrams))\n",
    "\n",
    "    unseen_prob = (N1 / N) / num_unseen if N > 0 else 1e-12\n",
    "\n",
    "    return smoothed_probs, unseen_prob\n",
    "\n",
    "# ---------------- Sentence Probability ----------------\n",
    "def sentence_logprob(sentence, smoothed_probs, unseen_prob, n):\n",
    "    words = [\"<s>\"] * (n - 1) + sentence.strip().split() + [\"</s>\"]  ## applying start and end of sentences\n",
    "    logp = 0.0\n",
    "    for i in range(len(words) - n + 1):\n",
    "        ngram = tuple(words[i:i + n])\n",
    "        prob = smoothed_probs.get(ngram, unseen_prob)\n",
    "        logp += math.log(prob if prob > 0 else 1e-12)   ##if smoothed prob is 0, take log of a small value\n",
    "    return logp\n",
    "\n",
    "# ---------------- File Processing ----------------\n",
    "def process_file(input_file, output_csv, uni, bi, tri, quad, uni_un, bi_un, tri_un, quad_un):\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f, \\\n",
    "         open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as out:\n",
    "        \n",
    "        writer = csv.writer(out)\n",
    "        writer.writerow([\"sentence\", \"unigram_logprob\", \"bigram_logprob\", \"trigram_logprob\", \"quadrigram_logprob\"])\n",
    "        \n",
    "        for i, line in enumerate(f, 1):\n",
    "            sentence = line.strip()\n",
    "            if not sentence:\n",
    "                continue\n",
    "            uni_lp = sentence_logprob(sentence, uni, uni_un, 1)\n",
    "            bi_lp = sentence_logprob(sentence, bi, bi_un, 2)\n",
    "            tri_lp = sentence_logprob(sentence, tri, tri_un, 3)\n",
    "            quad_lp = sentence_logprob(sentence, quad, quad_un, 4)\n",
    "            \n",
    "            writer.writerow([sentence, uni_lp, bi_lp, tri_lp, quad_lp])\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Processed {i} sentences from {input_file}\")\n",
    "\n",
    "# ---------------- Main ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Load counts from training set\n",
    "    unigrams = load_ngram_counts(1)\n",
    "    bigrams = load_ngram_counts(2)\n",
    "    trigrams = load_ngram_counts(3)\n",
    "    quadrigrams = load_ngram_counts(4)\n",
    "\n",
    "    vocab = get_vocabulary(unigrams)\n",
    "    V = len(vocab)\n",
    "\n",
    "    # Apply Good-Turing smoothing\n",
    "    uni_probs, uni_unseen = good_turing_smoothing(unigrams, V, 1)\n",
    "    bi_probs, bi_unseen = good_turing_smoothing(bigrams, V, 2)\n",
    "    tri_probs, tri_unseen = good_turing_smoothing(trigrams, V, 3)\n",
    "    quad_probs, quad_unseen = good_turing_smoothing(quadrigrams, V, 4)\n",
    "\n",
    "    print(\"Good-Turing models built.\")\n",
    "\n",
    "    # Compute sentence probabilities for validation and test\n",
    "    process_file(\"validation.txt\", \"validation_probs.csv\",\n",
    "                 uni_probs, bi_probs, tri_probs, quad_probs,\n",
    "                 uni_unseen, bi_unseen, tri_unseen, quad_unseen)\n",
    "\n",
    "    process_file(\"test.txt\", \"test_probs.csv\",\n",
    "                 uni_probs, bi_probs, tri_probs, quad_probs,\n",
    "                 uni_unseen, bi_unseen, tri_unseen, quad_unseen)\n",
    "\n",
    "    print(\"Sentence log-probabilities saved to validation_probs.csv and test_probs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aab1f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>unigram_logprob</th>\n",
       "      <th>bigram_logprob</th>\n",
       "      <th>trigram_logprob</th>\n",
       "      <th>quadrigram_logprob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>આગળ રાજીવે કહ્યું કે મને આ ફિલ્મ કરવાનો આનંદ એ...</td>\n",
       "      <td>-224.847594</td>\n",
       "      <td>-491.371379</td>\n",
       "      <td>-886.177848</td>\n",
       "      <td>-1382.079797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>અને કરેલાં વ્યવહારો કઈ રીતે દર્શાવવા, જેથી કર ...</td>\n",
       "      <td>-130.983638</td>\n",
       "      <td>-284.341029</td>\n",
       "      <td>-475.941343</td>\n",
       "      <td>-726.576650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>વાસ્તવિક ફેશન વલણ ચળકતા હાથ છે, જે ચમકતા સોના ...</td>\n",
       "      <td>-136.326965</td>\n",
       "      <td>-267.453882</td>\n",
       "      <td>-538.103259</td>\n",
       "      <td>-778.606157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>આ ઉપરાંત એક્ટ્રસ બાની અને લીઝા રેની વચ્ચેના બો...</td>\n",
       "      <td>-137.102001</td>\n",
       "      <td>-284.064090</td>\n",
       "      <td>-485.387381</td>\n",
       "      <td>-676.323635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>પાણપુરની મોબાઇલ શોપમાંથી રૂપિયા 70 હજારના મોબા...</td>\n",
       "      <td>-82.430779</td>\n",
       "      <td>-202.665324</td>\n",
       "      <td>-367.116529</td>\n",
       "      <td>-486.196637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>તે જરૂરી છે, તે કામ ન હતી \"તેના પોતાના ખાતર એક...</td>\n",
       "      <td>-97.987791</td>\n",
       "      <td>-209.637243</td>\n",
       "      <td>-349.890256</td>\n",
       "      <td>-596.159632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>જયાં તેમને છાતીમાં દુઃખાવો અને શ્વાસમાં તકલીફ ...</td>\n",
       "      <td>-93.343205</td>\n",
       "      <td>-161.654636</td>\n",
       "      <td>-273.037570</td>\n",
       "      <td>-484.139258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>ઘર ને ઝળહળવા માટે ,</td>\n",
       "      <td>-49.170553</td>\n",
       "      <td>-108.861620</td>\n",
       "      <td>-215.743625</td>\n",
       "      <td>-281.867989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>સૌથી મહત્ત્વપૂર્ણ વાત એ છે કે, રોકાણકારોએ ઇન્વ...</td>\n",
       "      <td>-163.884697</td>\n",
       "      <td>-349.020348</td>\n",
       "      <td>-589.921431</td>\n",
       "      <td>-1008.808841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>પૂર્વ જવાન રામકિશન સમાન હોદ્દા સમાન પેન્શન મુદ...</td>\n",
       "      <td>-174.133673</td>\n",
       "      <td>-341.126416</td>\n",
       "      <td>-603.347810</td>\n",
       "      <td>-894.326257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  unigram_logprob  \\\n",
       "0    આગળ રાજીવે કહ્યું કે મને આ ફિલ્મ કરવાનો આનંદ એ...      -224.847594   \n",
       "1    અને કરેલાં વ્યવહારો કઈ રીતે દર્શાવવા, જેથી કર ...      -130.983638   \n",
       "2    વાસ્તવિક ફેશન વલણ ચળકતા હાથ છે, જે ચમકતા સોના ...      -136.326965   \n",
       "3    આ ઉપરાંત એક્ટ્રસ બાની અને લીઝા રેની વચ્ચેના બો...      -137.102001   \n",
       "4    પાણપુરની મોબાઇલ શોપમાંથી રૂપિયા 70 હજારના મોબા...       -82.430779   \n",
       "..                                                 ...              ...   \n",
       "995  તે જરૂરી છે, તે કામ ન હતી \"તેના પોતાના ખાતર એક...       -97.987791   \n",
       "996  જયાં તેમને છાતીમાં દુઃખાવો અને શ્વાસમાં તકલીફ ...       -93.343205   \n",
       "997                                ઘર ને ઝળહળવા માટે ,       -49.170553   \n",
       "998  સૌથી મહત્ત્વપૂર્ણ વાત એ છે કે, રોકાણકારોએ ઇન્વ...      -163.884697   \n",
       "999  પૂર્વ જવાન રામકિશન સમાન હોદ્દા સમાન પેન્શન મુદ...      -174.133673   \n",
       "\n",
       "     bigram_logprob  trigram_logprob  quadrigram_logprob  \n",
       "0       -491.371379      -886.177848        -1382.079797  \n",
       "1       -284.341029      -475.941343         -726.576650  \n",
       "2       -267.453882      -538.103259         -778.606157  \n",
       "3       -284.064090      -485.387381         -676.323635  \n",
       "4       -202.665324      -367.116529         -486.196637  \n",
       "..              ...              ...                 ...  \n",
       "995     -209.637243      -349.890256         -596.159632  \n",
       "996     -161.654636      -273.037570         -484.139258  \n",
       "997     -108.861620      -215.743625         -281.867989  \n",
       "998     -349.020348      -589.921431        -1008.808841  \n",
       "999     -341.126416      -603.347810         -894.326257  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df_valid = pd.read_csv(\"validation_probs.csv\")\n",
    "df_test = pd.read_csv(\"test_probs.csv\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "448f6986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>unigram_logprob</th>\n",
       "      <th>bigram_logprob</th>\n",
       "      <th>trigram_logprob</th>\n",
       "      <th>quadrigram_logprob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>વાસ્તવિક અંકુશ રેખા નજીક આવેલા પેન્ગોગ ત્સો એટ...</td>\n",
       "      <td>-154.389792</td>\n",
       "      <td>-299.341855</td>\n",
       "      <td>-577.936643</td>\n",
       "      <td>-891.714668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#1.</td>\n",
       "      <td>-6.836237</td>\n",
       "      <td>-56.104956</td>\n",
       "      <td>-81.581451</td>\n",
       "      <td>-108.043697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>અને બીજાં નવા નિશાળિયા.</td>\n",
       "      <td>-29.758443</td>\n",
       "      <td>-105.562530</td>\n",
       "      <td>-170.693897</td>\n",
       "      <td>-223.618390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>આ ગામના વાલીઓએ ફીની બબાલથી બચવા કરી અનોખી પહેલ.</td>\n",
       "      <td>-85.194901</td>\n",
       "      <td>-218.421505</td>\n",
       "      <td>-343.487599</td>\n",
       "      <td>-449.684891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74 ડિગ્રી ઉત્તર અક્ષાંશ અને 104.</td>\n",
       "      <td>-65.418081</td>\n",
       "      <td>-154.719851</td>\n",
       "      <td>-257.283170</td>\n",
       "      <td>-336.620199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>..</td>\n",
       "      <td>-10.520790</td>\n",
       "      <td>-14.352074</td>\n",
       "      <td>-14.352074</td>\n",
       "      <td>-14.352074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>ગુરવિંદર સિંહ (ખેડૂત)- બે ઇજા અને ઢસડાવાના નિશ...</td>\n",
       "      <td>-65.092633</td>\n",
       "      <td>-239.882524</td>\n",
       "      <td>-385.803876</td>\n",
       "      <td>-540.218486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>થી શરૂ થઈને 399 રૂ.</td>\n",
       "      <td>-47.496788</td>\n",
       "      <td>-101.425329</td>\n",
       "      <td>-168.768514</td>\n",
       "      <td>-243.722973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>જપ્ત કરાયેલો વિદેશી દારૂની કિંમત આશરે રૂ.</td>\n",
       "      <td>-70.338676</td>\n",
       "      <td>-132.690521</td>\n",
       "      <td>-271.360805</td>\n",
       "      <td>-392.330664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>જરૂર પડયે અમે બલિદાન આપવા તૈયાર છીએ.</td>\n",
       "      <td>-66.441200</td>\n",
       "      <td>-129.722573</td>\n",
       "      <td>-197.382692</td>\n",
       "      <td>-316.592614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  unigram_logprob  \\\n",
       "0    વાસ્તવિક અંકુશ રેખા નજીક આવેલા પેન્ગોગ ત્સો એટ...      -154.389792   \n",
       "1                                                  #1.        -6.836237   \n",
       "2                              અને બીજાં નવા નિશાળિયા.       -29.758443   \n",
       "3      આ ગામના વાલીઓએ ફીની બબાલથી બચવા કરી અનોખી પહેલ.       -85.194901   \n",
       "4                     74 ડિગ્રી ઉત્તર અક્ષાંશ અને 104.       -65.418081   \n",
       "..                                                 ...              ...   \n",
       "995                                                 ..       -10.520790   \n",
       "996  ગુરવિંદર સિંહ (ખેડૂત)- બે ઇજા અને ઢસડાવાના નિશ...       -65.092633   \n",
       "997                                થી શરૂ થઈને 399 રૂ.       -47.496788   \n",
       "998          જપ્ત કરાયેલો વિદેશી દારૂની કિંમત આશરે રૂ.       -70.338676   \n",
       "999               જરૂર પડયે અમે બલિદાન આપવા તૈયાર છીએ.       -66.441200   \n",
       "\n",
       "     bigram_logprob  trigram_logprob  quadrigram_logprob  \n",
       "0       -299.341855      -577.936643         -891.714668  \n",
       "1        -56.104956       -81.581451         -108.043697  \n",
       "2       -105.562530      -170.693897         -223.618390  \n",
       "3       -218.421505      -343.487599         -449.684891  \n",
       "4       -154.719851      -257.283170         -336.620199  \n",
       "..              ...              ...                 ...  \n",
       "995      -14.352074       -14.352074          -14.352074  \n",
       "996     -239.882524      -385.803876         -540.218486  \n",
       "997     -101.425329      -168.768514         -243.722973  \n",
       "998     -132.690521      -271.360805         -392.330664  \n",
       "999     -129.722573      -197.382692         -316.592614  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e85e137",
   "metadata": {},
   "source": [
    "<h1>table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3260df1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unigram Table (first 10 rows):\n",
      "    C (MLE)      Nc        C*\n",
      "0        0       0  0.000000\n",
      "1        1  430533  0.393187\n",
      "2        2   84640  1.352942\n",
      "3        3   38171  2.344398\n",
      "4        4   22372  3.375425\n",
      "5        5   15103  4.377938\n",
      "6        6   11020  5.380853\n",
      "7        7    8471  6.289694\n",
      "8        8    6660  7.470270\n",
      "9        9    5528  8.420767\n",
      "\n",
      "Bigram Table (first 10 rows):\n",
      "    C (MLE)       Nc        C*\n",
      "0        0        0  0.000000\n",
      "1        1  4420859  0.229718\n",
      "2        2   507775  1.083687\n",
      "3        3   183423  2.075727\n",
      "4        4    95184  3.052771\n",
      "5        5    58115  4.013800\n",
      "6        6    38877  5.044062\n",
      "7        7    28014  6.075534\n",
      "8        8    21275  7.015981\n",
      "9        9    16585  8.027736\n",
      "\n",
      "Trigram Table (first 10 rows):\n",
      "    C (MLE)       Nc        C*\n",
      "0        0        0  0.000000\n",
      "1        1  8963253  0.108275\n",
      "2        2   485247  0.860933\n",
      "3        3   139255  1.849643\n",
      "4        4    64393  2.867082\n",
      "5        5    36924  3.832792\n",
      "6        6    23587  4.911901\n",
      "7        7    16551  5.807987\n",
      "8        8    12016  6.797187\n",
      "9        9     9075  8.044077\n",
      "\n",
      "Quadrigram Table (first 10 rows):\n",
      "    C (MLE)        Nc        C*\n",
      "0        0         0  0.000000\n",
      "1        1  11101111  0.057096\n",
      "2        2    316912  0.742777\n",
      "3        3     78465  1.807583\n",
      "4        4     35458  2.797958\n",
      "5        5     19842  3.860599\n",
      "6        6     12767  4.963656\n",
      "7        7      9053  5.790788\n",
      "8        8      6553  6.639097\n",
      "9        9      4834  8.158875\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "def good_turing_table(ngrams, top_k=100):\n",
    "    Nc = collections.Counter(ngrams.values())  # frequency of frequencies\n",
    "    rows = []\n",
    "\n",
    "    for c in range(top_k):\n",
    "        Nc_val = Nc.get(c, 0)\n",
    "        Nc_plus1 = Nc.get(c + 1, 0)\n",
    "\n",
    "        if Nc_val > 0:\n",
    "            c_star = (c + 1) * (Nc_plus1 / Nc_val) if Nc_plus1 > 0 else c ##count updation\n",
    "        else:\n",
    "            c_star = 0\n",
    "\n",
    "        rows.append([c, Nc_val, c_star])\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"C (MLE)\", \"Nc\", \"C*\"])\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load n-gram counts\n",
    "    unigrams = load_ngram_counts(1)\n",
    "    bigrams = load_ngram_counts(2)\n",
    "    trigrams = load_ngram_counts(3)\n",
    "    quadrigrams = load_ngram_counts(4)\n",
    "\n",
    "    # Build tables\n",
    "    uni_table   = good_turing_table(unigrams, 100)\n",
    "    bi_table    = good_turing_table(bigrams, 100)\n",
    "    tri_table   = good_turing_table(trigrams, 100)\n",
    "    quad_table  = good_turing_table(quadrigrams, 100)\n",
    "\n",
    "    # Save them\n",
    "    uni_table.to_csv(\"good_turing_table_unigrams.csv\", index=False)\n",
    "    bi_table.to_csv(\"good_turing_table_bigrams.csv\", index=False)\n",
    "    tri_table.to_csv(\"good_turing_table_trigrams.csv\", index=False)\n",
    "    quad_table.to_csv(\"good_turing_table_quadrigrams.csv\", index=False)\n",
    "\n",
    "    # Print preview\n",
    "    print(\"\\nUnigram Table (first 10 rows):\\n\", uni_table.head(10))\n",
    "    print(\"\\nBigram Table (first 10 rows):\\n\", bi_table.head(10))\n",
    "    print(\"\\nTrigram Table (first 10 rows):\\n\", tri_table.head(10))\n",
    "    print(\"\\nQuadrigram Table (first 10 rows):\\n\", quad_table.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddae20ea",
   "metadata": {},
   "source": [
    "<h1>Implement deleted interpolated smoothing technique for the quadrigram model and find\n",
    "the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37397b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleted-Interpolation: 100%|██████████| 11619213/11619213 [00:48<00:00, 241725.84quad/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted-interpolation lambdas (lambda1..lambda4): [0.40355213390901956, 0.38137513613787494, 0.15748241207594238, 0.0575903178771631]\n",
      "Evaluating on validation set...\n",
      "Validation Perplexity (interpolated quadrigram): 1921.6896\n",
      "Evaluating on test set...\n",
      "Test Perplexity (interpolated quadrigram): 2188.2764\n",
      "Lambdas saved to quad_interpolation_lambdas.json\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import collections\n",
    "import math\n",
    "import csv\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm \n",
    "\n",
    "# ---------------- Load Pickle ----------------\n",
    "def load_ngram_counts(n, folder=\".\"):\n",
    "    file_name = Path(folder) / f\"ngram_counts_{n}gram.pkl\"\n",
    "    with open(file_name, \"rb\") as f:\n",
    "        counts = pickle.load(f)\n",
    "    # Expect counts to be dict mapping tuple(word1,...,wordn) -> int\n",
    "    # For unigrams counts might be dict of (token,) -> count\n",
    "    return counts\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def get_total_unigram_tokens(unigrams):\n",
    "    # N = sum of unigram counts\n",
    "    return sum(unigrams.values())\n",
    "\n",
    "def safe_div(num, den):\n",
    "    if den <= 0:\n",
    "        return 0.0\n",
    "    return num / den\n",
    "\n",
    "# ---------------- Deleted interpolation lambdas ----------------\n",
    "def compute_deleted_interpolation_lambdas(unigrams, bigrams, trigrams, quadrigrams):\n",
    "    \n",
    "    acc = [0.0, 0.0, 0.0, 0.0]  # index 0 -> unigram weight, ... index 3 -> quad weight\n",
    "    # Unigrams keys: (w,), bigrams: (w1,w2), trigrams: (w1,w2,w3), quadrigrams: (w1,w2,w3,w4)\n",
    "\n",
    "    N_unigram_tokens = get_total_unigram_tokens(unigrams)\n",
    "    # iterate over all observed quadrigrams\n",
    "    for quad, c_quad in tqdm(quadrigrams.items(), desc=\"Deleted-Interpolation\", unit=\"quad\"):\n",
    "        c = c_quad\n",
    "        if c <= 0:\n",
    "            continue\n",
    "\n",
    "        w1, w2, w3, w4 = quad\n",
    "\n",
    "        # 4-gram leave-one-out conditional:\n",
    "        context4 = (w1, w2, w3)\n",
    "        c_context4 = trigrams.get(context4, 0)\n",
    "        p4 = 0.0\n",
    "        if c_context4 - 1 > 0:\n",
    "            p4 = safe_div(c_quad - 1, c_context4 - 1)\n",
    "\n",
    "        # 3-gram:\n",
    "        tri = (w2, w3, w4)\n",
    "        context3 = (w2, w3)\n",
    "        c_tri = trigrams.get(tri, 0)\n",
    "        c_context3 = bigrams.get(context3, 0)\n",
    "        p3 = 0.0\n",
    "        if c_context3 - 1 > 0:\n",
    "            p3 = safe_div(c_tri - 1, c_context3 - 1)\n",
    "\n",
    "        # 2-gram:\n",
    "        bi = (w3, w4)\n",
    "        context2 = (w3,)\n",
    "        c_bi = bigrams.get(bi, 0)\n",
    "        c_context2 = unigrams.get(context2, 0)\n",
    "        p2 = 0.0\n",
    "        if c_context2 - 1 > 0:\n",
    "            p2 = safe_div(c_bi - 1, c_context2 - 1)\n",
    "\n",
    "        # 1-gram:\n",
    "        unigram = (w4,)\n",
    "        c_uni = unigrams.get(unigram, 0)\n",
    "        p1 = 0.0\n",
    "        if N_unigram_tokens - 1 > 0:\n",
    "            p1 = safe_div(c_uni - 1, N_unigram_tokens - 1)\n",
    "\n",
    "        # choose best order\n",
    "        ps = [p1, p2, p3, p4]\n",
    "        # pick argmax; in tie, choose highest-order? standard is argmax; ties arbitrary\n",
    "        best_k = max(range(4), key=lambda k: ps[k])  # 0..3\n",
    "        acc[best_k] += c  # weight by count (or you can add 1 if preferred)\n",
    "\n",
    "    total = sum(acc)\n",
    "    if total == 0:\n",
    "        # fallback to uniform\n",
    "        lambdas = [0.25, 0.25, 0.25, 0.25]\n",
    "    else:\n",
    "        lambdas = [a / total for a in acc]\n",
    "\n",
    "    return lambdas\n",
    "\n",
    "# ---------------- Interpolated probability ----------------\n",
    "def interpolated_prob(w_prev3, w_prev2, w_prev1, w, unigrams, bigrams, trigrams, quadrigrams, lambdas):\n",
    "    # compute MLE conditional probabilities (non-deleted) at each order:\n",
    "    # P4 = c(w_prev3,w_prev2,w_prev1,w)/c(w_prev3,w_prev2,w_prev1)\n",
    "    c4 = quadrigrams.get((w_prev3, w_prev2, w_prev1, w), 0)\n",
    "    c_context4 = trigrams.get((w_prev3, w_prev2, w_prev1), 0)\n",
    "    p4 = safe_div(c4, c_context4)\n",
    "\n",
    "    c3 = trigrams.get((w_prev2, w_prev1, w), 0)\n",
    "    c_context3 = bigrams.get((w_prev2, w_prev1), 0)\n",
    "    p3 = safe_div(c3, c_context3)\n",
    "\n",
    "    c2 = bigrams.get((w_prev1, w), 0)\n",
    "    c_context2 = unigrams.get((w_prev1,), 0)\n",
    "    p2 = safe_div(c2, c_context2)\n",
    "\n",
    "    c1 = unigrams.get((w,), 0)\n",
    "    N = get_total_unigram_tokens(unigrams)\n",
    "    p1 = safe_div(c1, N)\n",
    "\n",
    "    lamb1, lamb2, lamb3, lamb4 = lambdas\n",
    "    return lamb1*p1 + lamb2*p2 + lamb3*p3 + lamb4*p4\n",
    "\n",
    "# ---------------- Sentence log-prob & perplexity ----------------\n",
    "def sentence_logprob_interpolated(sentence, unigrams, bigrams, trigrams, quadrigrams, lambdas, n=4):\n",
    "    tokens = sentence.strip().split()\n",
    "    # pad with start tokens\n",
    "    tokens = [\"<s>\"]*(n-1) + tokens + [\"</s>\"]\n",
    "    logp = 0.0\n",
    "    word_count = 0\n",
    "    for i in range(n-1, len(tokens)):\n",
    "        w = tokens[i]\n",
    "        w_prev1 = tokens[i-1] if i-1 >= 0 else \"<s>\"\n",
    "        w_prev2 = tokens[i-2] if i-2 >= 0 else \"<s>\"\n",
    "        w_prev3 = tokens[i-3] if i-3 >= 0 else \"<s>\"\n",
    "        prob = interpolated_prob(w_prev3, w_prev2, w_prev1, w,\n",
    "                                 unigrams, bigrams, trigrams, quadrigrams, lambdas)\n",
    "        if prob <= 0:\n",
    "            prob = 1e-12\n",
    "        logp += math.log(prob)\n",
    "        word_count += 1\n",
    "    return logp, word_count\n",
    "\n",
    "def evaluate_perplexity(file_path, unigrams, bigrams, trigrams, quadrigrams, lambdas):\n",
    "    total_logprob = 0.0\n",
    "    total_words = 0\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            s = line.strip()\n",
    "            if not s:\n",
    "                continue\n",
    "            lp, wc = sentence_logprob_interpolated(s, unigrams, bigrams, trigrams, quadrigrams, lambdas)\n",
    "            total_logprob += lp\n",
    "            total_words += wc\n",
    "\n",
    "    # perplexity = exp(- total_logprob / total_words)\n",
    "    avg_neg_log_likelihood = - total_logprob / total_words\n",
    "    perp = math.exp(avg_neg_log_likelihood)\n",
    "    return perp\n",
    "\n",
    "# ---------------- Main ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Load counts\n",
    "    unigrams = load_ngram_counts(1)\n",
    "    bigrams = load_ngram_counts(2)\n",
    "    trigrams = load_ngram_counts(3)\n",
    "    quadrigrams = load_ngram_counts(4)\n",
    "\n",
    "    # compute lambdas\n",
    "    lambdas = compute_deleted_interpolation_lambdas(unigrams, bigrams, trigrams, quadrigrams)\n",
    "    print(\"Deleted-interpolation lambdas (lambda1..lambda4):\", lambdas)\n",
    "\n",
    "    # Evaluate on validation set and optionally on test\n",
    "    val_file = \"validation.txt\"\n",
    "    test_file = \"test.txt\"\n",
    "\n",
    "    print(\"Evaluating on validation set...\")\n",
    "    val_ppl = evaluate_perplexity(val_file, unigrams, bigrams, trigrams, quadrigrams, lambdas)\n",
    "    print(f\"Validation Perplexity (interpolated quadrigram): {val_ppl:.4f}\")\n",
    "\n",
    "    print(\"Evaluating on test set...\")\n",
    "    test_ppl = evaluate_perplexity(test_file, unigrams, bigrams, trigrams, quadrigrams, lambdas)\n",
    "    print(f\"Test Perplexity (interpolated quadrigram): {test_ppl:.4f}\")\n",
    "\n",
    "    # Save lambdas\n",
    "    with open(\"quad_interpolation_lambdas.json\", \"w\", encoding=\"utf-8\") as out:\n",
    "        json.dump({\"lambdas\": lambdas}, out, indent=2)\n",
    "    print(\"Lambdas saved to quad_interpolation_lambdas.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
